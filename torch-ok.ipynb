{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For those who, like me, immediately open the code :)\n",
    "!pip3 install -r -U requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdAhRXwiVdtT"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBi0bwmqUZsN"
   },
   "outputs": [],
   "source": [
    "# to download a dataset from kaggle, can use opendatasets (lib will even unzip it right away)\n",
    "# my kaggle datasets at the link ðŸ˜ŠðŸ‘‰  https://www.kaggle.com/danilalekseev/datasets\n",
    "import opendatasets as od\n",
    "\n",
    "od.download(\"your link\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUjgy7q2xzwF"
   },
   "outputs": [],
   "source": [
    "# load the required libraries\n",
    "from loguru import logger\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WJvlRn4InDUa",
    "outputId": "762fcd37-bc59-49c0-df05-e9a209f2b02b"
   },
   "outputs": [],
   "source": [
    "# config logs\n",
    "logs_path = f\"./logs/torhok-{datetime.now()}.log\"\n",
    "logger.add(logs_path, format=\"{time} - {level} - {message}\")\n",
    "logger.info(f\"All logs are saved to the file \\\"{logs_path}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAt1SZe3USTT",
    "outputId": "94f3dda7-b89b-4ec5-af55-4bcb579e883b"
   },
   "outputs": [],
   "source": [
    "data_dir = './data/' # specify the path to the dataset\n",
    "train_dir = data_dir + '/train'\n",
    "test_dir = data_dir + '/test'\n",
    "val_dir = data_dir + '/val'\n",
    "\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "classes = sorted([_.name.split(\"/\")[-1] for _ in pathlib.Path(train_dir).iterdir()])\n",
    "\n",
    "train_count = len(glob.glob(train_dir + '/**/*.*'))\n",
    "test_count = len(glob.glob(test_dir + '/**/*.*'))\n",
    "val_count = len(glob.glob(val_dir + '/**/*.*'))\n",
    "\n",
    "\n",
    "mes = f\"All parameters have been declared\\n\\t\\\"{device}\\\" device detected\\n\\t\" +\\\n",
    "f\"classes = {', '.join(classes)}\\n\\t/train {train_count}\\n\\t/test {test_count}\\n\\t\" +\\\n",
    "f\"/val {val_count}\\n\\tbatch_size = {batch_size}\"\n",
    "logger.info(mes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ULx9Ckhx0Kd",
    "outputId": "a9af8941-9ce2-4981-a7d0-30cceb5f8342"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((150, 150)),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5, 0.5, 0.5], \n",
    "                          [0.5, 0.5, 0.5])])\n",
    "\n",
    "# loading Datasets with ImageFolder\n",
    "trainset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "valset = datasets.ImageFolder(val_dir, transform=transform)\n",
    "testset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# using image and form datasets, define a data loader.\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
    "\n",
    "logger.info(\"Images have been uploaded and transformed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xt7Xe__vx6eC",
    "outputId": "dab1fc59-7d07-4716-be22-c3c1ae06a61c"
   },
   "outputs": [],
   "source": [
    "#CNN Network\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Output size after convolution\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3, \n",
    "                             out_channels=12, \n",
    "                             kernel_size=3, \n",
    "                             stride=1, \n",
    "                             padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,\n",
    "                             out_channels=20,\n",
    "                             kernel_size=3,\n",
    "                             stride=1,\n",
    "                             padding=1)\n",
    "        self.relu2=nn.ReLU()    \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,\n",
    "                             out_channels=32,\n",
    "                             kernel_size=3,\n",
    "                             stride=1,\n",
    "                             padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,\n",
    "                          out_features=num_classes)\n",
    "        \n",
    "    # Direct feed function\n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "            \n",
    "        output = self.pool(output)\n",
    "            \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        output=self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "model = ConvNet(num_classes=len(classes)).to(device)\n",
    "\n",
    "logger.info(\"Model architecture:\\n\\n\" + str(model)+\"\\n\\n\")\n",
    "logger.info(\"CNN model declared successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vy26Arkgx8_B",
    "outputId": "a24a6be3-f2d9-4058-beb3-26f89acf8e4d"
   },
   "outputs": [],
   "source": [
    "# Optimizer & loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "logger.info(\"Optimizer & loss function declared successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "0eNd5GyUx_Qm",
    "outputId": "ebb9ae6a-55a7-4f55-aef6-60dab62ad1b3"
   },
   "outputs": [],
   "source": [
    "# Model training\n",
    "def train_classifier(epochs, print_every_iterration=100, \n",
    "                     save_mode_path=\"./torch_model.pth\"):\n",
    "    logger.debug(f\"Start training the model. Number of all epochs - {num_epochs}\")\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_accuracy = 0.0\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if i % print_every_iterration == 0:\n",
    "                logger.debug(f\"Iteration: {i}/{len(trainloader)}\")\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            train_loss += loss.cpu().data * images.size(0)\n",
    "            _, prediction = torch.max(outputs.data,1)\n",
    "            \n",
    "            train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        logger.info(f\"All iterations of epoch {epoch}/{epochs} have been completed\")\n",
    "            \n",
    "        train_accuracy = train_accuracy / train_count\n",
    "        train_loss = train_loss / train_count\n",
    "        \n",
    "        \n",
    "        # Evaluation on validation dataset\n",
    "        model.eval()\n",
    "        \n",
    "        val_accuracy = 0.0\n",
    "        for i, (images, labels) in enumerate(valloader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images.cuda())\n",
    "                labels = Variable(labels.cuda())\n",
    "                \n",
    "            outputs = model(images)\n",
    "            _, prediction = torch.max(outputs.data, 1)\n",
    "            val_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "        val_accuracy = val_accuracy / val_count\n",
    "        \n",
    "        \n",
    "        logger.debug(f'Epoch: {epoch}/{epochs}  Train Loss: {train_loss} Train Accuracy: {train_accuracy} Validation Accuracy: {val_accuracy}')\n",
    "        \n",
    "        # Save the best result of the model\n",
    "        if val_accuracy > best_accuracy:\n",
    "            torch.save(model.state_dict(), save_mode_path)\n",
    "            best_accuracy = val_accuracy\n",
    "\n",
    "        \n",
    "        logger.info(f\"Model training was successful\\nThe best result of the model has been saved in \\\"{save_mode_path}\\\"\")\n",
    "\n",
    "\n",
    "train_classifier(epochs=num_epochs, print_every_iterration=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcCIKEkFVhHg"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the required libraries\n",
    "from torchmetrics.functional import accuracy, precision_recall\n",
    "from torchmetrics import F1Score, MeanSquaredError\n",
    "from PIL import Image\n",
    "import random\n",
    "import glob\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./torch_model.pth\" # path to pytorch model\n",
    "images_info = {\"path\": \"./data/test/\", \"count\": 3} # path where the photos for tests are located & Ð°nd the quantity to be used\n",
    "classes = sorted([_.name.split(\"/\")[-1] for _ in pathlib.Path(images_info[\"path\"]).iterdir()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved pth model\n",
    "model = ConvNet(num_classes=len(classes))\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((150, 150)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "HtVIBzSAyJUS",
    "outputId": "76c7bca1-71fd-4bc8-83dd-cf6fff3015c2"
   },
   "outputs": [],
   "source": [
    "# get all the paths to the images, mix and take part\n",
    "testimgs = glob.glob(images_info[\"path\"] + '**/*.*')\n",
    "random.shuffle(testimgs)\n",
    "testimgs = testimgs[:images_info[\"count\"]]\n",
    "\n",
    "lables = \"true lables: \" + \" \".join([_.replace(images_info[\"path\"], \"\").split(\"/\")[0] for _ in testimgs])\n",
    "images = [[transform(Image.open(_)).numpy()] for _ in testimgs]\n",
    "\n",
    "images = torch.tensor(np.vstack(images))\n",
    "\n",
    "# displaying random images\n",
    "def imgshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "imgshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "print(lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the prediction of the neural network model\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('predicted: ', ' '.join(f'{classes[predicted[j]]:5s}' for j in range(images_info[\"count\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# collect information, y_true - correct data, y_pred - neural network predictions (takes time)\n",
    "y_true = []\n",
    "x_test = []\n",
    "print(\"Number of images\", len(glob.glob(images_info[\"path\"] + '**/*.*')))\n",
    "\n",
    "for imgpath in glob.glob(images_info[\"path\"] + '**/*.*'):\n",
    "    try:\n",
    "        y_true.append(classes.index(imgpath.replace(images_info[\"path\"], \"\").split(\"/\")[0]))\n",
    "        x_test.append([transform(Image.open(imgpath)).numpy()])\n",
    "    except Exception as error: # skip if an error occurred while processing the image\n",
    "        # print(repr(error), \"- passing img\")\n",
    "        pass\n",
    "\n",
    "y_true = torch.tensor(y_true)\n",
    "y_pred = torch.max(model(torch.tensor(np.vstack(x_test))), 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDcU13mIzEZa"
   },
   "outputs": [],
   "source": [
    "# get neural network quality metrics\n",
    "def metrics(y_true, y_pred):\n",
    "    # calculate the Accuracy\n",
    "    accurancy = accuracy(y_pred, y_true)\n",
    "    print(\"Accurancy:\", round(float(accurancy)*100, 3), \"%\")\n",
    "    \n",
    "    # calculate the Precision & Recall\n",
    "    precision, recall = map(float, precision_recall(y_pred, y_true))\n",
    "    print(\"Precision:\", round(precision*100, 3), \"%\")\n",
    "    print(\"Recall:\", round(recall*100, 3), \"%\")\n",
    "    \n",
    "    # calculate the F1Score\n",
    "    f1 = F1Score(num_classes=len(classes))\n",
    "    f1score = f1(y_pred, y_true)\n",
    "    print(\"F1Score:\", round(float(f1score)*100, 3), \"%\")\n",
    "    \n",
    "    # calculate the Mean Squared Error\n",
    "    mse = MeanSquaredError()\n",
    "    mean_squared_error = mse(y_pred, y_true)\n",
    "    print(\"Mean Squared Error:\", round(float(mean_squared_error)*100, 3), \"%\")\n",
    "\n",
    "metrics(y_true=y_true, y_pred=y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "dcCIKEkFVhHg"
   ],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
